\chapter{Trabalhos Relacionados}


No passado, a tarefa de Estimação Monocular de Profundidade não era abordada de forma direta. Um exemplo deste cenário é o trabalho de \citeonline{hoiem2005automatic}, em que o objetivo é reconstruir uma cena 3D em um ambiente virtual através de uma única imagem RGB. Apesar da finalidade não ser a construção de um mapa de profundidade, a reconstrução 3D de uma cena é diretamente ligada à informação de profundidade, portanto, esse trabalho é creditado em revisões bibliográficas do tema \cite{mertan2022single}. É considerado que um ambiente externo consiste de elementos fixos, o céu, um plano de chão e objetos verticais saindo deste plano. É realizada uma classificação de superpixels nas classes através de características pré-selecionadas manualmente, e os objetos são colocados em 3D através das mesmas.


Ainda nos primórdios da MDE, um dos primeiros trabalhos a se propor a estimar um mapa de profundidade métrico de uma única imagem RGB é o de \citeonline{saxena2005learning}. Filtros manualmente projetados são aplicados em pequenos pedaços de uma imagem de entrada para extrair características. Para cada parte, um valor de distância é estimado. Os filtros são então aplicados em múltiplas escalas para levar em consideração as pistas visuais globais e de partes adjacentes. Pesos maiores são atribuídos às características dos pedaços que ficam nas mesmas colunas, baseado na premissa de que as estruturas dos objetos observados são em sua maioria, verticais. Além disso, um modelo baseado em Campos Aleatórios de Markov (\textit{Markov Random Field} - MRF) é treinado de maneira supervisionada para estimar a profundidade a partir das características.


Algum tempo depois, outro trabalho publicado por \citeonline{saxena2008make3d}, adicionou um pressuposto pertinente ao estado da arte de MDE, que uma cena consiste de várias pequenas superfícies planas e a orientação e localização 3D dessa superfície podem ser utilizadas para calcular sua profundidade. Esse pressuposto é utilizado até hoje em motores gráficos que criam modelos de objetos complexos através de malhas triangulares. Novamente, é utilizado um modelo baseado em MRF treinado de maneira supervisionada. As características são obtidas através de filtros manualmente projetados e a contextualização global é considerada através de superpixels adjacentes.


Considerando o desenvolvimento do aprendizado profundo à época, \citeonline{eigen2014depth} introduziu o uso de redes neurais convolucionais para a tarefa de MDE, superando as técnicas anteriores. O problema foi formulado como um método de regressão com aprendizado supervisionado de um conjunto de duas redes neurais. A primeira é responsável por uma estimação grosseira do mapa de profundidade. Sendo composta por camadas convolucionais totalmente conectadas, possui a imagem toda como campo receptivo, utilizando melhor o contexto global, a custo de um grande custo computacional. A segunda rede neural é totalmente convolucional e possui como entrada o mapa da rede anterior, e tem como finalidade o ajuste fino do mapa de profundidade, operando através de filtros locais. Além disso foi utilizada uma função de perda com invariância em escala no espaço logarítmico.

O modelo de estimação de profundidade Midas foi apresentado por \citeonline{ranftl2020towards}, a pesquisa possui como principal contribuição o desenvolvimento de protocolos de mesclagem de conjuntos de dados de profundidade mesmo que suas anotações não sejam compatíveis. O núcleo dessa abordagem consiste em uma função que é invariante em escala e alcance em um processo de aprendizado multi-objetivo combinando dados de diferentes fontes. A arquitetura da rede consiste em uma estrutura baseada em ResNet em multi escala. Outra contribuição foi o emprego de filmes 3D para composição da base de dados de treinamento em larga escala, apesar de não apresentar anotação de profundidade, foi utilizado \textit{stereo matching} para rotulagem do conjunto de treino. 

Em \cite{birkl2023midas}, foi dado sequência ao trabalho anterior e apresentou-se novos modelos com diferentes codificadores, sendo a maioria baseado em transformadores de visão, fundamentando-se nos recentes avanços e resultados desta tecnologia. Os autores realizam uma comparação entre os transformadores BEiT, Swin, SwinV2, Next-ViT e LeViT considerando performance versus tempo de execução. Os resultados alcançados foram melhores que a versão puramente convolucional do modelo para  maior parte dos modelos. 

Em \cite{ke2024repurposing} foi apresentado um protocolo de \textit{fine tuning} de modelos de difusão latente pré-treinados para estimação relativa de profundidade sob qualquer circunstância. O protocolo, chamado de Marigold, contribui com o estado da arte sendo um dos trabalhos que investigou o uso de bases de dados de imagens sintéticas para treinamento, dado que estas não estariam propensas a erros de captura. Utilizou-se um modelo de difusão estável pré-treinado, e o ajuste do modelo é realizado utilizando uma função objetivo calculada no espaço latente entre a saída da U-Net e o ruído inicial. Outra contribuição do trabalho foi a aplicação de ruído retificado em multi-resolução para o processo de difusão. 

Na temática do uso de dados não rotulados em larga escala, os autores \citeonline{yang2024depthv1} construíram um modelo fundacional para MDE capaz de produzir imagens de profundidade em alta qualidade sob quaisquer circunstâncias, chamado de \textit{Depth Anything}. O uso de dados não rotulados é fundamentado em três principais vantagens: fácil e barata aquisição, diversidade de cenas e fácil rotulagem. O protocolo apresentado consiste em dois modelos. O primeiro, chamado de "professor", é treinado em um conjunto menor de imagens de profundidade com anotações. Em seguida, o modelo professor é usado para anotar os 62 milhões de imagens não rotuladas adquiridas de oito datasets públicos. O conjunto de dados final é por fim, utilizado para treinamento do modelo final. A arquitetura é baseada no modelo DINOv2 com pré-treinamento para segmentação semântica, o que auxilia ainda mais no processo de MDE.

Prosseguindo o trabalho anterior, em \cite{yang2024depth} é apresentado uma versão aprimorada do sistema \textit{Depth Anything}, que foca não somente em melhorar as métricas, mas em produzir predições mais robustas e com alto grau de detalhes. Esses objetivos são alcançados através do escalonamento do modelo professor e o uso de imagens exclusivamente sintéticas no seu processo de treinamento. 


As recentes pesquisas da área de estimação monocular de profundidade apresentaram uma variedade de técnicas robustas baseadas em aprendizado profundo. Neste cenário, este trabalho se propõe a realizar comparações entre os modelos do estado da arte por meio de métricas e aplicações.